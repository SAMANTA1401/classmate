{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03de0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879bc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import ImageCaptionLoader\n",
    "\n",
    "# list_image_urls = [\n",
    "#     \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Ara_ararauna_Luc_Viatour.jpg/1554px-Ara_ararauna_Luc_Viatour.jpg\",\n",
    "#     \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/1928_Model_A_Ford.jpg/640px-1928_Model_A_Ford.jpg\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "971b1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = ImageCaptionLoader(images=list_image_urls)\n",
    "# list_docs = loader.load()\n",
    "# list_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18545bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from PIL import Image\n",
    "\n",
    "# Image.open(requests.get(list_image_urls[0], stream=True).raw).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6923f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa9d6b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../artifacts/reinforcement_learning.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84bc8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Reinforcement Learning: The Unseen Driver in\\nAutonomous Vehicles\\nParth Goyal · Subscribe\\n9 min read · Nov 14, 2023\\nListen Share More\\nImagine this: You’re late for a meeting. You rush to your car and start the engine, but\\nthen you remember the daunting task ahead — navigating through the city’s peak\\nhour traffic. Now, imagine if your car could drive you to your destination while you\\nsit back and prepare for your meeting. This is not a scene from a sci-fi movie, but a\\nfuture that is being shaped by Reinforcement Learning (RL).\\nIn today’s article, we will:\\nJourney into the heart of Reinforcement Learning and its transformative role in\\nautonomous vehicles.\\nExplore the challenges and delve into real-world case studies.\\nLook ahead to the prospects of this technology.\\nWe’ll start by understanding the pivotal role of RL in autonomous vehicles, and\\nlearning how these invisible chauffeurs are making our roads safer. We’ll then\\ntackle the challenges head-on, discussing the hurdles and the innovative solutions\\nbeing developed to leap over them. Through case studies, we’ll see RL in action,\\nobserving how theory translates into practice in the real world. And finally, we’ll\\ncast our gaze into the future, speculating on how RL could revolutionize not just\\ntransportation, but our very way of life. So buckle up and join me on this exciting\\njourney into the world of Reinforcement Learning and autonomous vehicles! We’ll\\nGet unlimited access to the best of Medium for less than $1/week. Become a member\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 1/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='explore not only the challenges but also the immense possibilities that this\\ntechnology holds for our future. Let’s hit the road!\\nWhat is Reinforcement Learning\\nRL, a subset of artificial intelligence, is all about learning from interaction. It’s like\\nteaching a child to walk. The child stumbles and falls, but with each fall, it learns\\nsomething new, and one day it starts to walk. Similarly, an RL algorithm learns to\\nmake decisions by interacting with its environment. In the context of autonomous\\nvehicles, RL is the invisible chauffeur. It observes the road, and learns from every\\nturn, every stop, and every near-miss until it becomes proficient at driving.\\nThe Power of Reinforcement Learning\\nNow, you might be wondering why does this matter? Why should we care about RL\\nin autonomous vehicles? To answer that, let’s look at some numbers. The World\\nHealth Organization reports that approximately 1.35 million people die each year as\\na result of road traffic crashes. Now imagine if we could bring this number down\\nsignificantly. This is where RL comes into play. Autonomous vehicles, guided by RL\\nalgorithms, have the potential to make our roads safer. For instance, Waymo, an\\nautonomous driving technology company, reported in 2020 that their self-driving\\ncars were involved in 18 minor accidents during more than 20 million miles of\\ndriving — none of which were the fault of the self-driving car. So when we talk about\\nRL in autonomous vehicles, we’re not just talking about technology or convenience;\\nwe’re talking about saving lives. That’s why it matters.\\nOpen in app\\nSearch\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 2/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='The Role of RL in Autonomous Vehicles\\nEarlier, I gave you a scenario of a future where your car drives you to your\\ndestination while you sit back and relax. Now let’s delve into the mechanics of how\\nthis is made possible by Reinforcement Learning in autonomous vehicles.\\nIn the world of autonomous vehicles, the vehicle itself is an RL agent. This agent\\ninteracts with its environment, which includes everything from the roads and traffic\\nsignals to other vehicles and pedestrians. The agent observes the state of the\\nenvironment, takes an action based on its current knowledge or policy, and then\\nreceives feedback in the form of a reward or penalty. This feedback helps the agent\\nlearn the best actions to take in different situations.\\nLet’s break this down into some key aspects of autonomous driving:\\nRoute Planning: RL can be used to determine the most efficient route to a\\ndestination. The RL agent considers various factors such as distance, traffic\\nconditions, and road closures to plan the route.\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 3/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Obstacle Avoidance: One of the critical tasks for an autonomous vehicle is to\\nsafely navigate around obstacles. An RL agent learns to recognize different types\\nof obstacles and decides whether to steer around them, slow down, or stop\\ncompletely.\\nLane Changing: Changing lanes in heavy traffic can be challenging even for\\nhuman drivers. An RL agent learns when it’s safe to change lanes based on\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 4/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='factors like the speed and proximity of other vehicles.\\nTraffic Signal Adherence: RL agents are trained to recognize and respond\\nappropriately to traffic signals. They learn that stopping at a red light leads to a\\npositive reward (safety) while running a red light leads to a negative reward\\n(potential accident).\\nIn all these aspects, the key is interaction and learning from feedback. The RL agent\\ncontinually updates its knowledge or policy based on the feedback it receives from\\nits actions. Over time, this leads to an autonomous vehicle that can navigate\\ncomplex environments safely and efficiently. So, while our earlier scenario may\\nseem like science fiction, it’s a future that RL is helping us build today.\\nChallenges and Solutions in Applying RL to Autonomous Vehicles\\nWhile Reinforcement Learning holds immense potential in the realm of\\nautonomous vehicles, it’s not without its challenges. Let’s explore some of these\\nchallenges and the innovative solutions being developed to overcome them.\\nHigh Dimensionality of the State Space: The state space in an autonomous\\ndriving scenario is incredibly complex, with numerous variables such as the\\npositions and velocities of nearby vehicles, road conditions, traffic signals, and\\nmore. This high dimensionality can make it challenging for the RL agent to\\nlearn effectively.\\nSolution: Techniques like feature selection and dimensionality reduction can be\\nused to simplify the state space. These techniques help identify the most\\nrelevant features and reduce the dimensionality of the state space, making it\\neasier for the RL agent to learn.\\nNeed for Large Amounts of Training Data: RL algorithms typically require a large\\namount of training data to learn effectively. Collecting this data in real-world driving\\nscenarios can be time-consuming and expensive.\\nSolution: One potential solution is to use simulation environments for training.\\nThese environments can generate a vast amount of diverse and challenging\\nscenarios for the RL agent to learn from, without the need for real-world data\\ncollection.\\nSafety Concerns: Training an RL agent in real-world driving scenarios can be risky,\\nas the agent may make unsafe decisions during the learning process.\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 5/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Solution: Again, simulation environments provide a safe platform for training.\\nAdditionally, techniques like safe exploration can be used to ensure that the RL\\nagent safely explores its environment.\\nTransfer Learning: The ability to transfer what an RL agent has learned in one\\nenvironment (like a simulator) to another environment (like real-world driving) is a\\nsignificant challenge.\\nSolution: Techniques like domain adaptation and transfer learning are being\\ndeveloped to address this challenge. These techniques aim to enable an RL agent to\\napply what it has learned in one context to another context.\\nAll in all, while there are challenges in applying RL to autonomous vehicles,\\nresearchers are continually developing innovative solutions to overcome these\\nhurdles. The road ahead is challenging, but with every challenge comes an\\nopportunity for innovation.\\nCase Study #1\\nWaymo: Waymo, a subsidiary of Alphabet Inc., has been a pioneer in the\\napplication of Reinforcement Learning (RL) in autonomous vehicles. They have\\nconducted large-scale applications of a combined imitation and reinforcement\\nlearning approach in autonomous driving utilizing large amounts of real-world\\nurban human driving data. Their research has shown that while imitation can\\nperform well in low-difficulty scenarios that are well-covered by the demonstration\\ndata, combining imitation learning with reinforcement learning significantly\\nimproves robustness in the most challenging scenarios. Waymo has also developed\\na new simulator to help researchers train more realistic agents.\\nCase Study #2\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 6/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Tesla: Tesla is another major player that has been leveraging RL for their\\nautonomous vehicles. They have been using machine learning techniques,\\nincluding RL, to produce high-end autonomous driving systems. The specifics of\\ntheir approach are proprietary, but it’s known that they use large amounts of real-\\nworld driving data for training their models.\\nCase Study #3\\nAcademic Research: There has been significant academic research on the\\napplication of RL to autonomous vehicles. For instance, a study published in IEEE\\nTransactions on Intelligent Transportation Systems provided insight into the\\nhierarchical motion planning problem and described the basics of Deep\\nReinforcement Learning (DRL). The study also discussed the main elements of\\ndesigning such a system, including the modeling of the environment, the modeling\\nabstractions, the description of the state and the perception models, the appropriate\\nreward, and the realization of the underlying neural network. Another study\\nexplored the challenges associated with navigating complex T-intersections in dense\\ntraffic scenarios for autonomous vehicles (AVs). The researchers used a lower-cost,\\nsingle-agent approach based on the Twin Delayed Deep Deterministic Policy\\nGradient (TD3) reinforcement learning algorithm.\\nFuture Prospects of RL in Autonomous Vehicles\\nThe future of RL in autonomous vehicles is incredibly promising. As we continue to\\nrefine RL algorithms and develop more sophisticated training environments, we can\\nexpect to see significant advancements in the performance and safety of\\nautonomous vehicles.\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 7/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='1. Improved Performance: As RL algorithms become more sophisticated, they will\\nbe able to handle increasingly complex driving scenarios. This includes\\nnavigating through heavy traffic, dealing with unpredictable human drivers, and\\neven responding to emergencies. The result will be autonomous vehicles that\\ncan drive as well, if not better than, human drivers.\\n2. Enhanced Safety: One of the primary goals of autonomous vehicles is to\\nimprove road safety. With RL, autonomous vehicles can learn from every driving\\nexperience, including near-misses and accidents. This continual learning\\nprocess will lead to safer driving behaviors and could significantly reduce the\\nnumber of road accidents.\\n3. Efficient Traffic Management: RL could also play a role in traffic management.\\nBy optimizing route planning and traffic signal timing, RL could help reduce\\ntraffic congestion and improve overall transportation efficiency.\\n4. Personalized Driving Experience: In the future, RL could enable autonomous\\nvehicles to adapt to the preferences of individual passengers. For example, some\\npassengers might prefer a more conservative driving style, while others might\\nwant to get to their destination as quickly as possible. RL algorithms could learn\\nthese preferences and adjust their driving style accordingly.\\nConclusion\\nIn conclusion, Reinforcement Learning (RL) is a powerful tool in the realm of\\nautonomous vehicles, enabling these vehicles to learn from their environment and\\nimprove their performance over time. However, the application of RL in this field is\\nnot without its challenges. The high dimensionality of the state space, the need for\\nlarge amounts of training data, safety concerns, and the ability to transfer learning\\nfrom one environment to another are all significant hurdles that need to be\\novercome.\\nDespite these challenges, we have seen numerous innovative solutions being\\ndeveloped, from using simulation environments for safe and efficient training to\\ntechniques like feature selection and dimensionality reduction for managing\\ncomplex state spaces. Case studies from companies like Waymo and Tesla, as well as\\nacademic research, have demonstrated the potential of RL in improving the\\nperformance and safety of autonomous vehicles.\\nLooking Ahead\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 8/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='There’s still much to explore. The field of RL in autonomous vehicles is vast and\\never-evolving. I’m particularly interested in how advancements in RL algorithms\\nand training techniques could lead to even safer and more efficient autonomous\\nvehicles. Could there be a breakthrough in RL that revolutionizes autonomous\\ndriving? Or perhaps a novel application of RL that we haven’t even thought of yet?\\nMoreover, I’m curious about how these advancements could impact our everyday\\nlives. How will improved autonomous driving change our commute? Could it lead to\\na future where traffic accidents are a thing of the past?\\nAs research in this field continues, it’s anticipated that more robust and effective\\nsolutions will be developed to address these challenges. And I look forward to being\\npart of that journey, exploring these questions, and sharing my findings with you. So\\nstay tuned for more exciting insights into the world of Reinforcement Learning and\\nAutonomous Vehicles!\\nSubscribe\\nWritten by Parth Goyal\\n10 Followers · 5 Following\\nA 17-year-old AI enthusiast & programmer. Passionate about learning and pushing the boundaries of\\ninnovation.\\nNo responses yet\\nShubhankar Samanta\\nReinforcement Learning Autonomous Vehicles\\nW h a t  a r e  y o u r  t h o u g h t s ?\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 9/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='More from Parth Goyal\\nMode Collapse in GANs: A Roadblock to AI’s Creative Potential\\nImagine a world where AI becomes an artist, a designer, a creator. A world where AI can\\ngenerate images so realistic that they are…\\nOct 29, 2023\\nParth Goyal\\n3\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 10/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='See all from Parth Goyal\\nRecommended from Medium\\nUnlocking Secrets with AI: The Revolutionary World of Adversarial Neural\\nCryptography\\nImagine this: you’re sending a confidential message to a friend. You hit the send button, and\\nyour message is transformed into a jumble of…\\nMar 9, 2024\\nParth Goyal\\n3\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 11/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='Reinforcement Learning from scratch\\nI believe that the best way of learning a new algorithms is actually trying to implement them\\nfrom scratch. When I do this I often find…\\nFeb 8\\nIn by\\nYou Can Make Money With AI Without Quitting Your Job\\nI’m doing it, 2 hours a day\\nMarek Michalik\\n21\\nLearn AI for Profit Nipuna Maduranga\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 12/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Mar 25\\nReinforcement Learning: Double Deep Q-Networks\\nBrief overview and PyTorch showcase\\nDec 11, 2024\\nOpenAI Gym and Gymnasium: Reinforcement Learning Environments for\\nPython\\n3.2K 152\\nSebastien Deliot\\n1\\nNeural pAi\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Mar 3\\nSolving the Gridworld Problem Using Reinforcement Learning in Python\\nReinforcement Learning (RL) is an exciting and powerful paradigm that allows agents to learn\\noptimal behaviors through trial and error. In…\\nOct 14, 2024\\nVitality Learning\\n1\\nSebastian Carlos\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 14/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='See more recommendations\\nFired From Meta After 1 Week: Here’s All The Dirt I Got\\nThis is not just another story of a disgruntled ex-employee. I’m not shying away from the\\nserious corporate espionage or the ethical…\\nJan 8 20K 454\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 15/15')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57448d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba009ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81775e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ[\"langchain_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6194501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name=\"allenai/specter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9447429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becc00b38db24a00bc24070e47a97a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TutorEngine\\tenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789eaccd3f954c998b8b28f30a6fb9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd9bbfe825c4c6ba9cf1876619beb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83241c7aee5e49269eb55f801cc622a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a517d1998e41d19809e72b17986791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153c17855e8a48e98dfa386de3414c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9588b827b2db4120b76769e132c4d5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef9ad82095640ccad630ff7de4047e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06344b93d329426d863f0227d55cbfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f0970e4ce54eb7b2b445a6f29b9fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec8226d8a8a49efb65618373b7a3634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c54b1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize RAG components\n",
    "# # embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# # \"allenai/specter\"\n",
    "# # \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "# vector_store = None\n",
    "# # llm = HuggingFacePipeline.from_model_id(\n",
    "# #     model_id=\"facebook/opt-350m\",\n",
    "# #     task=\"text-generation\",\n",
    "# #     pipeline_kwargs={\"max_new_tokens\": 200}\n",
    "# # )\n",
    "\n",
    "# model = ChatHuggingFace(model=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec14e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "\n",
    "vector_store = FAISS.from_documents(splits, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e631c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1818b540282a41da926a5178f412d61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TutorEngine\\tenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--facebook--opt-350m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191fd645483041ce85eca928690efb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13541786e57b4b2d8afd3911083cccf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c88e4c730064b4dabe59b4c0c9beca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fccb0a218264b809afbfd297453e298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548424d5e2604050a40bb47458706266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fce4ebf1a94569897603eef2750016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/662M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c61f62c8d84006b515909bee142d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"facebook/opt-350m\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "348a161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm1 = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"max_new_tokens\": 200}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'nvidia/Llama-3_1-Nemotron-Ultra-253B-v1' # text generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baa73417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_9024\\3420448295.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"summarize the document\")\n"
     ]
    }
   ],
   "source": [
    "# Retrieve relevant documents\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.get_relevant_documents(\"summarize the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4201cbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tesla: Tesla is another major player that has been leveraging RL for their\\nautonomous vehicles. They have been using machine learning techniques,\\nincluding RL, to produce high-end autonomous driving systems. The specifics of\\ntheir approach are proprietary, but it’s known that they use large amounts of real-\\nworld driving data for training their models.\\nCase Study #3\\nAcademic Research: There has been significant academic research on the\\napplication of RL to autonomous vehicles. For instance, a study published in IEEE\\nTransactions on Intelligent Transportation Systems provided insight into the\\nhierarchical motion planning problem and described the basics of Deep\\nReinforcement Learning (DRL). The study also discussed the main elements of\\ndesigning such a system, including the modeling of the environment, the modeling\\nabstractions, the description of the state and the perception models, the appropriate\\nreward, and the realization of the underlying neural network. Another study',\n",
       " 'Mar 25\\nReinforcement Learning: Double Deep Q-Networks\\nBrief overview and PyTorch showcase\\nDec 11, 2024\\nOpenAI Gym and Gymnasium: Reinforcement Learning Environments for\\nPython\\n3.2K 152\\nSebastien Deliot\\n1\\nNeural pAi\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15',\n",
       " 'Mar 3\\nSolving the Gridworld Problem Using Reinforcement Learning in Python\\nReinforcement Learning (RL) is an exciting and powerful paradigm that allows agents to learn\\noptimal behaviors through trial and error. In…\\nOct 14, 2024\\nVitality Learning\\n1\\nSebastian Carlos\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 14/15']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content.page_content for content in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b67cf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine retrieved content\n",
    "context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Define prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"Generate a concise summary of the following content:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "prompt = prompt_template.format(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42b1f8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Tesla: Tesla is another major player that has been leveraging RL for their\n",
       "autonomous vehicles. They have been using machine learning techniques,\n",
       "including RL, to produce high-end autonomous driving systems. The specifics of\n",
       "their approach are proprietary, but it’s known that they use large amounts of real-\n",
       "world driving data for training their models.\n",
       "Case Study #3\n",
       "Academic Research: There has been significant academic research on the\n",
       "application of RL to autonomous vehicles. For instance, a study published in IEEE\n",
       "Transactions on Intelligent Transportation Systems provided insight into the\n",
       "hierarchical motion planning problem and described the basics of Deep\n",
       "Reinforcement Learning (DRL). The study also discussed the main elements of\n",
       "designing such a system, including the modeling of the environment, the modeling\n",
       "abstractions, the description of the state and the perception models, the appropriate\n",
       "reward, and the realization of the underlying neural network. Another study\n",
       "Mar 25\n",
       "Reinforcement Learning: Double Deep Q-Networks\n",
       "Brief overview and PyTorch showcase\n",
       "Dec 11, 2024\n",
       "OpenAI Gym and Gymnasium: Reinforcement Learning Environments for\n",
       "Python\n",
       "3.2K 152\n",
       "Sebastien Deliot\n",
       "1\n",
       "Neural pAi\n",
       "4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\n",
       "https://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15\n",
       "Mar 3\n",
       "Solving the Gridworld Problem Using Reinforcement Learning in Python\n",
       "Reinforcement Learning (RL) is an exciting and powerful paradigm that allows agents to learn\n",
       "optimal behaviors through trial and error. In…\n",
       "Oct 14, 2024\n",
       "Vitality Learning\n",
       "1\n",
       "Sebastian Carlos\n",
       "4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\n",
       "https://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 14/15"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f45ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate a concise summary of the following content:\\n\\nTesla: Tesla is another major player that has been leveraging RL for their\\nautonomous vehicles. They have been using machine learning techniques,\\nincluding RL, to produce high-end autonomous driving systems. The specifics of\\ntheir approach are proprietary, but it’s known that they use large amounts of real-\\nworld driving data for training their models.\\nCase Study #3\\nAcademic Research: There has been significant academic research on the\\napplication of RL to autonomous vehicles. For instance, a study published in IEEE\\nTransactions on Intelligent Transportation Systems provided insight into the\\nhierarchical motion planning problem and described the basics of Deep\\nReinforcement Learning (DRL). The study also discussed the main elements of\\ndesigning such a system, including the modeling of the environment, the modeling\\nabstractions, the description of the state and the perception models, the appropriate\\nreward, and the realization of the underlying neural network. Another study\\nMar 25\\nReinforcement Learning: Double Deep Q-Networks\\nBrief overview and PyTorch showcase\\nDec 11, 2024\\nOpenAI Gym and Gymnasium: Reinforcement Learning Environments for\\nPython\\n3.2K 152\\nSebastien Deliot\\n1\\nNeural pAi\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15\\nMar 3\\nSolving the Gridworld Problem Using Reinforcement Learning in Python\\nReinforcement Learning (RL) is an exciting and powerful paradigm that allows agents to learn\\noptimal behaviors through trial and error. In…\\nOct 14, 2024\\nVitality Learning\\n1\\nSebastian Carlos\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 14/15\\n\\nSummary:'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b529c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('generations', [[Generation(text='Generate a concise summary of the following content:\\n\\nTesla: Tesla is another major player that has been leveraging RL for their\\nautonomous vehicles. They have been using machine learning techniques,\\nincluding RL, to produce high-end autonomous driving systems. The specifics of\\ntheir approach are proprietary, but it’s known that they use large amounts of real-\\nworld driving data for training their models.\\nCase Study #3\\nAcademic Research: There has been significant academic research on the\\napplication of RL to autonomous vehicles. For instance, a study published in IEEE\\nTransactions on Intelligent Transportation Systems provided insight into the\\nhierarchical motion planning problem and described the basics of Deep\\nReinforcement Learning (DRL). The study also discussed the main elements of\\ndesigning such a system, including the modeling of the environment, the modeling\\nabstractions, the description of the state and the perception models, the appropriate\\nreward, and the realization of the underlying neural network. Another study\\nMar 25\\nReinforcement Learning: Double Deep Q-Networks\\nBrief overview and PyTorch showcase\\nDec 11, 2024\\nOpenAI Gym and Gymnasium: Reinforcement Learning Environments for\\nPython\\n3.2K 152\\nSebastien Deliot\\n1\\nNeural pAi\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15\\nMar 3\\nSolving the Gridworld Problem Using Reinforcement Learning in Python\\nReinforcement Learning (RL) is an exciting and powerful paradigm that allows agents to learn\\noptimal behaviors through trial and error. In…\\nOct 14, 2024\\nVitality Learning\\n1\\nSebastian Carlos\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 14/15\\n\\nSummary:\\n\\nThe following content is a summary of the following content.\\n\\nTesla: Tesla is another major player that has been leveraging RL for their\\nautonomous vehicles. They have been using machine learning techniques,\\nincluding RL, to produce high-end autonomous driving systems. The specifics of\\ntheir approach are proprietary, but it’s known that they use large amounts of real-world\\ndriving data for training their models.\\nCase Study #3\\nAcademic Research: There has been significant academic research on the\\napplication of RL to autonomous vehicles. For instance, a study published in IEEE\\nTransactions on Intelligent Transportation Systems provided insight into the\\nhierarchical motion planning problem and described the basics of Deep\\nReinforcement Learning (DRL). The study also discussed the main elements of\\ndesigning such a system, including the modeling of the environment, the modeling\\nabstractions, the description of the state and the perception models, the appropriate\\nreward,')]])\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m llm.generate([prompt], stream=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# logger.debug(f\"Streaming chunk: {chunk}\")\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(chunk)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m0.1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TutorEngine\\tenv\\Lib\\asyncio\\tasks.py:655\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    651\u001b[39m h = loop.call_later(delay,\n\u001b[32m    652\u001b[39m                     futures._set_result_unless_cancelled,\n\u001b[32m    653\u001b[39m                     future, result)\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    657\u001b[39m     h.cancel()\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    " # Generate summary with streaming\n",
    "for chunk in llm.generate([prompt], stream=True):\n",
    "    # logger.debug(f\"Streaming chunk: {chunk}\")\n",
    "    print(chunk)\n",
    "    await asyncio.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "790ad898",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"]=GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59949a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm3 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c24a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_9024\\2223590295.py:41: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = rag_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Summary:\n",
      "You are an expert summarizer. Based on the following context, provide a concise and informative summary of the document.\n",
      "\n",
      "Context:\n",
      "Context:\n",
      "See more recommendations\n",
      "Fired From Meta After 1 Week: Here’s All The Dirt I Got\n",
      "This is not just another story of a disgruntled ex-employee. I’m not shying away from the\n",
      "serious corporate espionage or the ethical…\n",
      "Jan 8 20K 454\n",
      "4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\n",
      "https://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 15/15\n",
      "\n",
      "Context:\n",
      "See all from Parth Goyal\n",
      "Recommended from Medium\n",
      "Unlocking Secrets with AI: The Revolutionary World of Adversarial Neural\n",
      "Cryptography\n",
      "Imagine this: you’re sending a confidential message to a friend. You hit the send button, and\n",
      "your message is transformed into a jumble of…\n",
      "Mar 9, 2024\n",
      "Parth Goyal\n",
      "3\n",
      "4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\n",
      "https://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 11/15\n",
      "\n",
      "Context:\n",
      "Mar 25\n",
      "Reinforcement Learning: Double Deep Q-Networks\n",
      "Brief overview and PyTorch showcase\n",
      "Dec 11, 2024\n",
      "OpenAI Gym and Gymnasium: Reinforcement Learning Environments for\n",
      "Python\n",
      "3.2K 152\n",
      "Sebastien Deliot\n",
      "1\n",
      "Neural pAi\n",
      "4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\n",
      "https://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15\n",
      "\n",
      "Context:\n",
      "Reinforcement Learning: The Unseen Driver in\n",
      "Autonomous Vehicles\n",
      "Parth Goyal · Subscribe\n",
      "9 min read · Nov 14, 2023\n",
      "Listen Share More\n",
      "Imagine this: You’re late for a meeting. You rush to your car and start the engine, but\n",
      "then you remember the daunting task ahead — navigating through the city’s peak\n",
      "hour traffic. Now, imagine if your car could drive you to your destination while you\n",
      "sit back and prepare for your meeting. This is not a scene from a sci-fi movie, but a\n",
      "future that is being shaped by Reinforcement Learning (RL).\n",
      "In today’s article, we will:\n",
      "Journey into the heart of Reinforcement Learning and its transformative role in\n",
      "autonomous vehicles.\n",
      "Explore the challenges and delve into real-world case studies.\n",
      "Look ahead to the prospects of this technology.\n",
      "We’ll start by understanding the pivotal role of RL in autonomous vehicles, and\n",
      "learning how these invisible chauffeurs are making our roads safer. We’ll then\n",
      "\n",
      "Summary:\n",
      "Reinforcement Learning: Double Deep Q-Networks\n",
      "Brief overview and PyTorch showcase\n",
      "Dec 11, 2024\n",
      "OpenAI Gym and Gymnasium: Reinforcement Learning Environments for\n",
      "Python\n",
      "3.2K 152\n",
      "Sebastien Deliot\n",
      "1\n",
      "Neural pAi\n",
      "4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\n",
      "https://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15\n",
      "\n",
      "Context:\n",
      "Reinforcement Learning: Double Deep Q-Networks\n",
      "Brief overview and PyTorch showcase\n",
      "Dec 11, 2024\n",
      "OpenAI Gym and Gymnasium: Reinforcement Learning Environments for\n",
      "Python\n",
      "3.2K 152\n",
      "Sebastien Deliot\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 1. Load and Ingest Document\n",
    "loader = PyPDFLoader(\"../artifacts/reinforcement_learning.pdf\")  # Replace with your PDF path\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 2. Embed Text\n",
    "# embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "# vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "# 3. Retrieval (Implicit Query: Summarize the Document)\n",
    "# For a simple summary, we might just pass all relevant chunks.\n",
    "# For a more targeted summary, you might need a more sophisticated retrieval strategy.\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4}) # Retrieve top 4 relevant chunks\n",
    "\n",
    "# 4 & 5. Generation with RAG\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-16k\") # Or another suitable LLM\n",
    "\n",
    "# Define a prompt for summarization with context\n",
    "prompt_template = \"\"\"You are an expert summarizer. Based on the following context, provide a concise and informative summary of the document.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Summary:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
    "\n",
    "rag_chain = RetrievalQA.from_llm(llm, retriever=retriever, prompt=PROMPT) # \"stuff\" combines all retrieved docs into the context\n",
    "\n",
    "# Implicit Query: Summarize the document\n",
    "query = \"Summarize this document.\" # Although the retrieval is based on the chunks, the final prompt asks for a summary.\n",
    "\n",
    "summary = rag_chain.run(query)\n",
    "\n",
    "print(\"Document Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ffab2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Reinforcement Learning: The Unseen Driver in\\nAutonomous Vehicles\\nParth Goyal · Subscribe\\n9 min read · Nov 14, 2023\\nListen Share More\\nImagine this: You’re late for a meeting. You rush to your car and start the engine, but\\nthen you remember the daunting task ahead — navigating through the city’s peak\\nhour traffic. Now, imagine if your car could drive you to your destination while you\\nsit back and prepare for your meeting. This is not a scene from a sci-fi movie, but a\\nfuture that is being shaped by Reinforcement Learning (RL).\\nIn today’s article, we will:\\nJourney into the heart of Reinforcement Learning and its transformative role in\\nautonomous vehicles.\\nExplore the challenges and delve into real-world case studies.\\nLook ahead to the prospects of this technology.\\nWe’ll start by understanding the pivotal role of RL in autonomous vehicles, and\\nlearning how these invisible chauffeurs are making our roads safer. We’ll then'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='learning how these invisible chauffeurs are making our roads safer. We’ll then\\ntackle the challenges head-on, discussing the hurdles and the innovative solutions\\nbeing developed to leap over them. Through case studies, we’ll see RL in action,\\nobserving how theory translates into practice in the real world. And finally, we’ll\\ncast our gaze into the future, speculating on how RL could revolutionize not just\\ntransportation, but our very way of life. So buckle up and join me on this exciting\\njourney into the world of Reinforcement Learning and autonomous vehicles! We’ll\\nGet unlimited access to the best of Medium for less than $1/week. Become a member\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 1/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='explore not only the challenges but also the immense possibilities that this\\ntechnology holds for our future. Let’s hit the road!\\nWhat is Reinforcement Learning\\nRL, a subset of artificial intelligence, is all about learning from interaction. It’s like\\nteaching a child to walk. The child stumbles and falls, but with each fall, it learns\\nsomething new, and one day it starts to walk. Similarly, an RL algorithm learns to\\nmake decisions by interacting with its environment. In the context of autonomous\\nvehicles, RL is the invisible chauffeur. It observes the road, and learns from every\\nturn, every stop, and every near-miss until it becomes proficient at driving.\\nThe Power of Reinforcement Learning\\nNow, you might be wondering why does this matter? Why should we care about RL\\nin autonomous vehicles? To answer that, let’s look at some numbers. The World\\nHealth Organization reports that approximately 1.35 million people die each year as'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='Health Organization reports that approximately 1.35 million people die each year as\\na result of road traffic crashes. Now imagine if we could bring this number down\\nsignificantly. This is where RL comes into play. Autonomous vehicles, guided by RL\\nalgorithms, have the potential to make our roads safer. For instance, Waymo, an\\nautonomous driving technology company, reported in 2020 that their self-driving\\ncars were involved in 18 minor accidents during more than 20 million miles of\\ndriving — none of which were the fault of the self-driving car. So when we talk about\\nRL in autonomous vehicles, we’re not just talking about technology or convenience;\\nwe’re talking about saving lives. That’s why it matters.\\nOpen in app\\nSearch\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 2/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='The Role of RL in Autonomous Vehicles\\nEarlier, I gave you a scenario of a future where your car drives you to your\\ndestination while you sit back and relax. Now let’s delve into the mechanics of how\\nthis is made possible by Reinforcement Learning in autonomous vehicles.\\nIn the world of autonomous vehicles, the vehicle itself is an RL agent. This agent\\ninteracts with its environment, which includes everything from the roads and traffic\\nsignals to other vehicles and pedestrians. The agent observes the state of the\\nenvironment, takes an action based on its current knowledge or policy, and then\\nreceives feedback in the form of a reward or penalty. This feedback helps the agent\\nlearn the best actions to take in different situations.\\nLet’s break this down into some key aspects of autonomous driving:\\nRoute Planning: RL can be used to determine the most efficient route to a\\ndestination. The RL agent considers various factors such as distance, traffic'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='destination. The RL agent considers various factors such as distance, traffic\\nconditions, and road closures to plan the route.\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 3/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Obstacle Avoidance: One of the critical tasks for an autonomous vehicle is to\\nsafely navigate around obstacles. An RL agent learns to recognize different types\\nof obstacles and decides whether to steer around them, slow down, or stop\\ncompletely.\\nLane Changing: Changing lanes in heavy traffic can be challenging even for\\nhuman drivers. An RL agent learns when it’s safe to change lanes based on\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 4/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='factors like the speed and proximity of other vehicles.\\nTraffic Signal Adherence: RL agents are trained to recognize and respond\\nappropriately to traffic signals. They learn that stopping at a red light leads to a\\npositive reward (safety) while running a red light leads to a negative reward\\n(potential accident).\\nIn all these aspects, the key is interaction and learning from feedback. The RL agent\\ncontinually updates its knowledge or policy based on the feedback it receives from\\nits actions. Over time, this leads to an autonomous vehicle that can navigate\\ncomplex environments safely and efficiently. So, while our earlier scenario may\\nseem like science fiction, it’s a future that RL is helping us build today.\\nChallenges and Solutions in Applying RL to Autonomous Vehicles\\nWhile Reinforcement Learning holds immense potential in the realm of\\nautonomous vehicles, it’s not without its challenges. Let’s explore some of these'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='autonomous vehicles, it’s not without its challenges. Let’s explore some of these\\nchallenges and the innovative solutions being developed to overcome them.\\nHigh Dimensionality of the State Space: The state space in an autonomous\\ndriving scenario is incredibly complex, with numerous variables such as the\\npositions and velocities of nearby vehicles, road conditions, traffic signals, and\\nmore. This high dimensionality can make it challenging for the RL agent to\\nlearn effectively.\\nSolution: Techniques like feature selection and dimensionality reduction can be\\nused to simplify the state space. These techniques help identify the most\\nrelevant features and reduce the dimensionality of the state space, making it\\neasier for the RL agent to learn.\\nNeed for Large Amounts of Training Data: RL algorithms typically require a large\\namount of training data to learn effectively. Collecting this data in real-world driving\\nscenarios can be time-consuming and expensive.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='scenarios can be time-consuming and expensive.\\nSolution: One potential solution is to use simulation environments for training.\\nThese environments can generate a vast amount of diverse and challenging\\nscenarios for the RL agent to learn from, without the need for real-world data\\ncollection.\\nSafety Concerns: Training an RL agent in real-world driving scenarios can be risky,\\nas the agent may make unsafe decisions during the learning process.\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 5/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Solution: Again, simulation environments provide a safe platform for training.\\nAdditionally, techniques like safe exploration can be used to ensure that the RL\\nagent safely explores its environment.\\nTransfer Learning: The ability to transfer what an RL agent has learned in one\\nenvironment (like a simulator) to another environment (like real-world driving) is a\\nsignificant challenge.\\nSolution: Techniques like domain adaptation and transfer learning are being\\ndeveloped to address this challenge. These techniques aim to enable an RL agent to\\napply what it has learned in one context to another context.\\nAll in all, while there are challenges in applying RL to autonomous vehicles,\\nresearchers are continually developing innovative solutions to overcome these\\nhurdles. The road ahead is challenging, but with every challenge comes an\\nopportunity for innovation.\\nCase Study #1\\nWaymo: Waymo, a subsidiary of Alphabet Inc., has been a pioneer in the'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Case Study #1\\nWaymo: Waymo, a subsidiary of Alphabet Inc., has been a pioneer in the\\napplication of Reinforcement Learning (RL) in autonomous vehicles. They have\\nconducted large-scale applications of a combined imitation and reinforcement\\nlearning approach in autonomous driving utilizing large amounts of real-world\\nurban human driving data. Their research has shown that while imitation can\\nperform well in low-difficulty scenarios that are well-covered by the demonstration\\ndata, combining imitation learning with reinforcement learning significantly\\nimproves robustness in the most challenging scenarios. Waymo has also developed\\na new simulator to help researchers train more realistic agents.\\nCase Study #2\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 6/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Tesla: Tesla is another major player that has been leveraging RL for their\\nautonomous vehicles. They have been using machine learning techniques,\\nincluding RL, to produce high-end autonomous driving systems. The specifics of\\ntheir approach are proprietary, but it’s known that they use large amounts of real-\\nworld driving data for training their models.\\nCase Study #3\\nAcademic Research: There has been significant academic research on the\\napplication of RL to autonomous vehicles. For instance, a study published in IEEE\\nTransactions on Intelligent Transportation Systems provided insight into the\\nhierarchical motion planning problem and described the basics of Deep\\nReinforcement Learning (DRL). The study also discussed the main elements of\\ndesigning such a system, including the modeling of the environment, the modeling\\nabstractions, the description of the state and the perception models, the appropriate\\nreward, and the realization of the underlying neural network. Another study'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='reward, and the realization of the underlying neural network. Another study\\nexplored the challenges associated with navigating complex T-intersections in dense\\ntraffic scenarios for autonomous vehicles (AVs). The researchers used a lower-cost,\\nsingle-agent approach based on the Twin Delayed Deep Deterministic Policy\\nGradient (TD3) reinforcement learning algorithm.\\nFuture Prospects of RL in Autonomous Vehicles\\nThe future of RL in autonomous vehicles is incredibly promising. As we continue to\\nrefine RL algorithms and develop more sophisticated training environments, we can\\nexpect to see significant advancements in the performance and safety of\\nautonomous vehicles.\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 7/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='1. Improved Performance: As RL algorithms become more sophisticated, they will\\nbe able to handle increasingly complex driving scenarios. This includes\\nnavigating through heavy traffic, dealing with unpredictable human drivers, and\\neven responding to emergencies. The result will be autonomous vehicles that\\ncan drive as well, if not better than, human drivers.\\n2. Enhanced Safety: One of the primary goals of autonomous vehicles is to\\nimprove road safety. With RL, autonomous vehicles can learn from every driving\\nexperience, including near-misses and accidents. This continual learning\\nprocess will lead to safer driving behaviors and could significantly reduce the\\nnumber of road accidents.\\n3. Efficient Traffic Management: RL could also play a role in traffic management.\\nBy optimizing route planning and traffic signal timing, RL could help reduce\\ntraffic congestion and improve overall transportation efficiency.\\n4. Personalized Driving Experience: In the future, RL could enable autonomous'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='4. Personalized Driving Experience: In the future, RL could enable autonomous\\nvehicles to adapt to the preferences of individual passengers. For example, some\\npassengers might prefer a more conservative driving style, while others might\\nwant to get to their destination as quickly as possible. RL algorithms could learn\\nthese preferences and adjust their driving style accordingly.\\nConclusion\\nIn conclusion, Reinforcement Learning (RL) is a powerful tool in the realm of\\nautonomous vehicles, enabling these vehicles to learn from their environment and\\nimprove their performance over time. However, the application of RL in this field is\\nnot without its challenges. The high dimensionality of the state space, the need for\\nlarge amounts of training data, safety concerns, and the ability to transfer learning\\nfrom one environment to another are all significant hurdles that need to be\\novercome.\\nDespite these challenges, we have seen numerous innovative solutions being'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='overcome.\\nDespite these challenges, we have seen numerous innovative solutions being\\ndeveloped, from using simulation environments for safe and efficient training to\\ntechniques like feature selection and dimensionality reduction for managing\\ncomplex state spaces. Case studies from companies like Waymo and Tesla, as well as\\nacademic research, have demonstrated the potential of RL in improving the\\nperformance and safety of autonomous vehicles.\\nLooking Ahead\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 8/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='There’s still much to explore. The field of RL in autonomous vehicles is vast and\\never-evolving. I’m particularly interested in how advancements in RL algorithms\\nand training techniques could lead to even safer and more efficient autonomous\\nvehicles. Could there be a breakthrough in RL that revolutionizes autonomous\\ndriving? Or perhaps a novel application of RL that we haven’t even thought of yet?\\nMoreover, I’m curious about how these advancements could impact our everyday\\nlives. How will improved autonomous driving change our commute? Could it lead to\\na future where traffic accidents are a thing of the past?\\nAs research in this field continues, it’s anticipated that more robust and effective\\nsolutions will be developed to address these challenges. And I look forward to being\\npart of that journey, exploring these questions, and sharing my findings with you. So\\nstay tuned for more exciting insights into the world of Reinforcement Learning and\\nAutonomous Vehicles!\\nSubscribe'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Autonomous Vehicles!\\nSubscribe\\nWritten by Parth Goyal\\n10 Followers · 5 Following\\nA 17-year-old AI enthusiast & programmer. Passionate about learning and pushing the boundaries of\\ninnovation.\\nNo responses yet\\nShubhankar Samanta\\nReinforcement Learning Autonomous Vehicles\\nW h a t  a r e  y o u r  t h o u g h t s ?\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 9/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='More from Parth Goyal\\nMode Collapse in GANs: A Roadblock to AI’s Creative Potential\\nImagine a world where AI becomes an artist, a designer, a creator. A world where AI can\\ngenerate images so realistic that they are…\\nOct 29, 2023\\nParth Goyal\\n3\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 10/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='See all from Parth Goyal\\nRecommended from Medium\\nUnlocking Secrets with AI: The Revolutionary World of Adversarial Neural\\nCryptography\\nImagine this: you’re sending a confidential message to a friend. You hit the send button, and\\nyour message is transformed into a jumble of…\\nMar 9, 2024\\nParth Goyal\\n3\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 11/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='Reinforcement Learning from scratch\\nI believe that the best way of learning a new algorithms is actually trying to implement them\\nfrom scratch. When I do this I often find…\\nFeb 8\\nIn by\\nYou Can Make Money With AI Without Quitting Your Job\\nI’m doing it, 2 hours a day\\nMarek Michalik\\n21\\nLearn AI for Profit Nipuna Maduranga\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 12/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Mar 25\\nReinforcement Learning: Double Deep Q-Networks\\nBrief overview and PyTorch showcase\\nDec 11, 2024\\nOpenAI Gym and Gymnasium: Reinforcement Learning Environments for\\nPython\\n3.2K 152\\nSebastien Deliot\\n1\\nNeural pAi\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 13/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Mar 3\\nSolving the Gridworld Problem Using Reinforcement Learning in Python\\nReinforcement Learning (RL) is an exciting and powerful paradigm that allows agents to learn\\noptimal behaviors through trial and error. In…\\nOct 14, 2024\\nVitality Learning\\n1\\nSebastian Carlos\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 14/15'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-04-10T12:42:09+00:00', 'title': 'Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium', 'moddate': '2025-04-10T12:42:09+00:00', 'source': '../artifacts/reinforcement_learning.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='See more recommendations\\nFired From Meta After 1 Week: Here’s All The Dirt I Got\\nThis is not just another story of a disgruntled ex-employee. I’m not shying away from the\\nserious corporate espionage or the ethical…\\nJan 8 20K 454\\n4/10/25, 6:12 PM Reinforcement Learning: The Unseen Driver in Autonomous Vehicles | by Parth Goyal | Medium\\nhttps://medium.com/@parth082006/reinforcement-learning-the-unseen-driver-in-autonomous-vehicles-df308305fd4d 15/15')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116cbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
